{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU 사용하는 만큼만 사용\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        # 프로그램 시작시에 메모리 증가가 설정되어야만 합니다\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "import skimage.io\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Bidirectional, LSTM,GRU, Dense, Lambda, Activation, BatchNormalization, Dropout, ZeroPadding2D, Add\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow import keras\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_list(df,img_path,max_size):\n",
    "    \"\"\"\n",
    "        이미지와 텍스트를 호출 후 각 x,y list에 담는 함수로 실제 (54,540,3) 형태로 들어가게 된다.\n",
    "        \n",
    "        df : 데이터 프레임\n",
    "        img_path : 이미지 있는 경로들\n",
    "        max_size : resize 할 이미지 사이즈, (width, height) 순으로 들어가야 함\n",
    "    \"\"\"\n",
    "    \n",
    "    dataset_id_list = df[['name', 'ans']]\n",
    "    dataset_id_list = dataset_id_list.values.tolist()\n",
    "    \n",
    "    # 사진은 X 값을 Y에 저장\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    #image to array\n",
    "    for name, ans  in tqdm(dataset_id_list):\n",
    "        image_dir = img_path + name\n",
    "        img = cv2.imread(image_dir)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = (img/255.)\n",
    "        img = cv2.resize(img, dsize=max_size, interpolation=cv2.INTER_AREA)\n",
    "        img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        img = img.reshape(max_size[1] ,max_size[0],1)\n",
    "        X.append(img)        \n",
    "        img_ans = np.array(ans)\n",
    "        img_ans = img_ans.tolist()\n",
    "        Y.append(img_ans)  \n",
    "    \n",
    "    #numpy change\n",
    "    X = np.array(X, dtype = np.float32)\n",
    "    Y = np.array(Y)\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_char(text):\n",
    "    for ch in text:\n",
    "        if not ch in characters:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    \"\"\"Generates batches from a given dataset.\n",
    "    \n",
    "    Args:\n",
    "        data: training or validation data\n",
    "        labels: corresponding labels\n",
    "        char_map: dictionary mapping char to labels\n",
    "        batch_size: size of a single batch\n",
    "        img_width: width of the resized\n",
    "        img_height: height of the resized\n",
    "        downsample_factor: by what factor did the CNN downsample the images\n",
    "        max_length: maximum length of any captcha\n",
    "        shuffle: whether to shuffle data or not after each epoch\n",
    "    Returns:\n",
    "        batch_inputs: a dictionary containing batch inputs \n",
    "        batch_labels: a batch of corresponding labels \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 data,\n",
    "                 labels,\n",
    "                 char_map,\n",
    "                 batch_size=16,\n",
    "                 img_width=540,\n",
    "                 img_height=54,\n",
    "                 downsample_factor=4,\n",
    "                 max_length=5,\n",
    "                 shuffle=True\n",
    "                ):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.char_map = char_map\n",
    "        self.batch_size = batch_size\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.downsample_factor = downsample_factor\n",
    "        self.max_length = max_length\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(data))    \n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.data) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 1. Get the next batch indices\n",
    "        curr_batch_idx = self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "        \n",
    "        # 2. This isn't necessary but it can help us save some memory\n",
    "        # as not all batches the last batch may not have elements\n",
    "        # equal to the batch_size \n",
    "        batch_len = len(curr_batch_idx)\n",
    "        \n",
    "        # 3. Instantiate batch arrays\n",
    "        batch_images = np.ones((batch_len, self.img_width, self.img_height, 1),\n",
    "                               dtype=np.float32)\n",
    "        batch_labels = np.ones((batch_len, self.max_length), dtype=np.float32)\n",
    "        input_length = np.ones((batch_len, 1), dtype=np.int64) * \\\n",
    "                                (self.img_width // self.downsample_factor - 2)\n",
    "        label_length = np.zeros((batch_len, 1), dtype=np.int64)\n",
    "        \n",
    "        for j, idx in enumerate(curr_batch_idx):\n",
    "            # 1. Get the image and transpose it\n",
    "            img = self.data[idx].T\n",
    "            # 2. Add extra dimenison\n",
    "            img = np.expand_dims(img, axis=-1)\n",
    "            \n",
    "            # 3. Get the correpsonding label\n",
    "            text = self.labels[idx]\n",
    "            \n",
    "            # 4. Include the pair only if the captcha is valid\n",
    "            if is_valid_char(text):\n",
    "                label = [self.char_map[ch] for ch in text]\n",
    "                batch_images[j] = img\n",
    "                for index, val in enumerate(label):\n",
    "                    batch_labels[j][index] = val\n",
    "                label_length[j] = len(text)\n",
    "        \n",
    "        batch_inputs = {\n",
    "                'input_data': batch_images,\n",
    "                'input_label': batch_labels,\n",
    "                'input_length': input_length,\n",
    "                'label_length': label_length,\n",
    "                }\n",
    "        return batch_inputs, np.zeros(batch_len).astype(np.float32)\n",
    "        \n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv call\n",
    "groups_folder_path = '/home/workspace/data/.train/.task157/train/'\n",
    "df = pd.read_csv('/home/workspace/data/.train/.task157/train/train.csv',sep=',')\n",
    "# datasetcsv\n",
    "\n",
    "# ans 항목 NaN값인 애들 제거\n",
    "index_nan = df[df['ans'].isnull() == True].index\n",
    "df.drop(index_nan, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "# Store all the characters in a set\n",
    "characters = set()\n",
    "\n",
    "for vals in list(df['ans']):\n",
    "    for ch in vals:\n",
    "        characters.add(ch)\n",
    "\n",
    "# Sort the characters        \n",
    "characters = sorted(characters)\n",
    "print(f\"characters len : {len(characters)}\")\n",
    "\n",
    "char_to_labels = {char:idx for idx, char in enumerate(characters)}\n",
    "labels_to_char = {val:key for key, val in char_to_labels.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size for training and validation\n",
    "batch_size = 4\n",
    "\n",
    "# Desired image dimensions\n",
    "img_width=540\n",
    "img_height=54 \n",
    "\n",
    "# Factor  by which the image is going to be downsampled\n",
    "# by the convolutional blocks\n",
    "downsample_factor=4\n",
    "\n",
    "# Maximum length of any captcha in the data\n",
    "max_length=28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTCLayer(layers.Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.loss_fn = keras.backend.ctc_batch_cost\n",
    "\n",
    "    def call(self, y_true, y_pred, input_length, label_length):\n",
    "        # Compute the training-time loss value and add it\n",
    "        # to the layer using `self.add_loss()`.\n",
    "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
    "        self.add_loss(loss)\n",
    "        \n",
    "        # On test time, just return the computed loss\n",
    "        return loss\n",
    "\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    # Inputs to the model\n",
    "    input_img = layers.Input(shape=(img_width, img_height,1),\n",
    "                            name='input_data',\n",
    "                            dtype='float32')\n",
    "    labels = layers.Input(name='input_label', shape=[max_length], dtype='float32')\n",
    "    input_length = layers.Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = layers.Input(name='label_length', shape=[1], dtype='int64')\n",
    "    \n",
    "    # First conv block\n",
    "    \n",
    "    x = layers.Conv2D(32,\n",
    "               (3,3),\n",
    "               kernel_initializer='he_normal',\n",
    "               padding='same',\n",
    "               name='Conv1')(input_img)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D((2,2), name='pool1')(x)\n",
    "    \n",
    "    # Second conv block\n",
    "    x = layers.Conv2D(64,\n",
    "               (3,3),\n",
    "               kernel_initializer='he_normal',\n",
    "               padding='same',\n",
    "               name='Conv2')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D((2,2), name='pool2')(x)\n",
    "    \n",
    "    # We have used two max pool with pool size and strides of 2.\n",
    "    # Hence, downsampled feature maps are 4x smaller. The number of\n",
    "    # filters in the last layer is 64. Reshape accordingly before\n",
    "    # passing it to RNNs\n",
    "    new_shape = ((img_width // 4), (img_height // 4)*64)\n",
    "    x = layers.Reshape(target_shape=new_shape, name='reshape')(x)\n",
    "    x = layers.Dense(1024, activation='relu', name='dense1')(x)\n",
    "    x = BatchNormalization(name='batchnorm1')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    \n",
    "    \n",
    "    # RNNs\n",
    "    x = layers.Bidirectional(layers.LSTM(512,\n",
    "                                         return_sequences=True,\n",
    "                                         dropout=0.2))(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(256,\n",
    "                                         return_sequences=True,\n",
    "                                         dropout=0.2))(x)\n",
    "    \n",
    "    # Predictions\n",
    "#     x = BatchNormalization(name='batchnorm3')(x)\n",
    "    x = layers.Dense(len(characters)+1,\n",
    "              activation='softmax', \n",
    "              name='dense2',\n",
    "              kernel_initializer='he_normal')(x)\n",
    "    \n",
    "    \n",
    "    # Calculate CTC\n",
    "    output = CTCLayer(name='ctc_loss')(labels, x, input_length, label_length)\n",
    "    \n",
    "    # Define the model\n",
    "    model = keras.models.Model(inputs=[input_img,\n",
    "                                       labels,\n",
    "                                       input_length,\n",
    "                                       label_length],\n",
    "                                outputs=output,\n",
    "                                name='ocr_model_v1')\n",
    "    \n",
    "    # Optimizer\n",
    "    opti = keras.optimizers.Adam(lr=0.0001, epsilon=0.001,decay=1e-5, clipnorm=1.)\n",
    "#     sgd = keras.optimizers.SGD(learning_rate=0.002,decay=1e-6,momentum=0.9,nesterov=True,clipnorm=5)\n",
    "    \n",
    "    # Compile the model and return \n",
    "    model.compile(optimizer=opti)\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '11'\n",
    "mc = ModelCheckpoint(f'best_model_v{version}.h5', monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss',patience=5)\n",
    "# lrfn = build_lrfn()\n",
    "# lr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import KFold\n",
    "random_seed = 2020\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3) # Fold 수\n",
    "index=1\n",
    "max_size = (540,54)\n",
    "img_path = '/home/workspace/data/.train/.task157/train/'\n",
    "for train,val in kf.split(df):\n",
    "    print('Fold'+ str(index))\n",
    "    train_df = df.iloc[train]\n",
    "    valid_df = df.iloc[val]\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    valid_df = valid_df.reset_index(drop=True)\n",
    "        \n",
    "    print(\"Part1 dataframe to list\")\n",
    "    train_x, train_y = df_to_list(train_df, img_path, max_size)\n",
    "    valid_x, valid_y = df_to_list(valid_df, img_path, max_size)\n",
    "    \n",
    "    print(\"Part2 train/valid generator set\", end='...')\n",
    "    # Get a generator object for the training data\n",
    "    train_data_generator = DataGenerator(data=train_x,\n",
    "                                         labels=train_y,\n",
    "                                         char_map=char_to_labels,\n",
    "                                         batch_size=batch_size,\n",
    "                                         img_width=img_width,\n",
    "                                         img_height=img_height,\n",
    "                                         downsample_factor=downsample_factor,\n",
    "                                         max_length=max_length,\n",
    "                                         shuffle=True\n",
    "                                        )\n",
    "\n",
    "    # Get a generator object for the validation data \n",
    "    valid_data_generator = DataGenerator(data=valid_x,\n",
    "                                         labels=valid_y,\n",
    "                                         char_map=char_to_labels,\n",
    "                                         batch_size=batch_size,\n",
    "                                         img_width=img_width,\n",
    "                                         img_height=img_height,\n",
    "                                         downsample_factor=downsample_factor,\n",
    "                                         max_length=max_length,\n",
    "                                         shuffle=False\n",
    "                                        )\n",
    "    print(\"Done!\")\n",
    "    \n",
    "    print(\"Part3 model training\")\n",
    "    model.fit(train_data_generator,\n",
    "              validation_data=valid_data_generator,\n",
    "                epochs=30, batch_size=batch_size,callbacks=[early_stopping,mc])\n",
    "    \n",
    "    model.save(f\"Fold_{index}_model_v{version}.h5\")\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
