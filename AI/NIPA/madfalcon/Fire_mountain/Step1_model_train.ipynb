{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "from tqdm.notebook import tqdm\n",
    "from glob import glob\n",
    "import skimage.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n",
      "------------------------------------------------------------\n",
      "num of parameter :  58627913\n",
      "num of trainable_ parameter : 58627913\n",
      "------------------------------------------------------------\n",
      "[0.006/10] loss(0.1207580715417862) elapsed 0:00:05.233684 expected per epoch 0:14:01.576387\n",
      "[0.012/10] loss(2.5110464096069336) elapsed 0:00:04.393844 expected per epoch 0:11:46.530115\n",
      "[0.019/10] loss(0.039254944771528244) elapsed 0:00:04.387552 expected per epoch 0:11:45.518362\n",
      "[0.025/10] loss(1.5738407373428345) elapsed 0:00:04.633549 expected per epoch 0:12:25.074679\n",
      "[0.031/10] loss(0.264758437871933) elapsed 0:00:04.700886 expected per epoch 0:12:35.902469\n",
      "[0.037/10] loss(0.08470045775175095) elapsed 0:00:04.758462 expected per epoch 0:12:45.160690\n",
      "[0.044/10] loss(0.44786757230758667) elapsed 0:00:04.746003 expected per epoch 0:12:43.157282\n",
      "[0.050/10] loss(0.08198951184749603) elapsed 0:00:04.738768 expected per epoch 0:12:41.993894\n",
      "[0.056/10] loss(0.32552868127822876) elapsed 0:00:04.552804 expected per epoch 0:12:12.090883\n",
      "[0.062/10] loss(0.06138552352786064) elapsed 0:00:04.490972 expected per epoch 0:12:02.148298\n",
      "[0.068/10] loss(0.08772419393062592) elapsed 0:00:04.411684 expected per epoch 0:11:49.398787\n",
      "[0.075/10] loss(0.046079568564891815) elapsed 0:00:04.414208 expected per epoch 0:11:49.804646\n",
      "[0.081/10] loss(0.09679004549980164) elapsed 0:00:04.408038 expected per epoch 0:11:48.812510\n",
      "[0.087/10] loss(0.1000620573759079) elapsed 0:00:04.614352 expected per epoch 0:12:21.987802\n",
      "[0.093/10] loss(0.05965603515505791) elapsed 0:00:04.760163 expected per epoch 0:12:45.434210\n",
      "[0.100/10] loss(0.10124906897544861) elapsed 0:00:04.652549 expected per epoch 0:12:28.129879\n",
      "[0.106/10] loss(0.37074652314186096) elapsed 0:00:04.413103 expected per epoch 0:11:49.626962\n",
      "[0.112/10] loss(1.3260983228683472) elapsed 0:00:04.416834 expected per epoch 0:11:50.226907\n",
      "[0.118/10] loss(1.6859681606292725) elapsed 0:00:04.416742 expected per epoch 0:11:50.212114\n",
      "[0.124/10] loss(0.19497835636138916) elapsed 0:00:04.404380 expected per epoch 0:11:48.224304\n",
      "[0.131/10] loss(0.338422954082489) elapsed 0:00:04.414836 expected per epoch 0:11:49.905629\n",
      "[0.137/10] loss(0.2449176162481308) elapsed 0:00:04.404746 expected per epoch 0:11:48.283157\n",
      "[0.143/10] loss(0.16363899409770966) elapsed 0:00:04.413257 expected per epoch 0:11:49.651726\n",
      "[0.149/10] loss(0.15845538675785065) elapsed 0:00:04.411311 expected per epoch 0:11:49.338809\n",
      "[0.155/10] loss(0.12817271053791046) elapsed 0:00:04.413680 expected per epoch 0:11:49.719744\n",
      "[0.162/10] loss(0.07981087267398834) elapsed 0:00:04.468728 expected per epoch 0:11:58.571462\n",
      "[0.168/10] loss(0.11358334124088287) elapsed 0:00:04.774837 expected per epoch 0:12:47.793790\n",
      "[0.174/10] loss(1.4197936058044434) elapsed 0:00:04.501669 expected per epoch 0:12:03.868375\n",
      "[0.180/10] loss(0.05742887035012245) elapsed 0:00:04.737991 expected per epoch 0:12:41.868953\n",
      "[0.187/10] loss(0.42427730560302734) elapsed 0:00:04.494544 expected per epoch 0:12:02.722675\n",
      "[0.193/10] loss(0.07883551716804504) elapsed 0:00:04.407292 expected per epoch 0:11:48.692554\n",
      "[0.199/10] loss(0.35851916670799255) elapsed 0:00:04.417042 expected per epoch 0:11:50.260354\n",
      "[0.205/10] loss(0.13023974001407623) elapsed 0:00:04.508301 expected per epoch 0:12:04.934801\n",
      "[0.211/10] loss(0.10775192081928253) elapsed 0:00:04.470833 expected per epoch 0:11:58.909946\n",
      "[0.218/10] loss(0.1068454384803772) elapsed 0:00:04.483581 expected per epoch 0:12:00.959825\n",
      "[0.224/10] loss(0.30705973505973816) elapsed 0:00:04.470992 expected per epoch 0:11:58.935514\n",
      "[0.230/10] loss(0.06981493532657623) elapsed 0:00:04.761927 expected per epoch 0:12:45.717862\n",
      "[0.236/10] loss(0.11174372583627701) elapsed 0:00:04.500881 expected per epoch 0:12:03.741665\n",
      "[0.243/10] loss(0.31178098917007446) elapsed 0:00:04.472367 expected per epoch 0:11:59.156614\n",
      "[0.249/10] loss(0.06997256726026535) elapsed 0:00:04.511241 expected per epoch 0:12:05.407553\n",
      "[0.255/10] loss(0.10974804311990738) elapsed 0:00:04.419321 expected per epoch 0:11:50.626817\n",
      "[0.261/10] loss(0.04719607159495354) elapsed 0:00:04.412743 expected per epoch 0:11:49.569074\n",
      "[0.267/10] loss(0.07299388200044632) elapsed 0:00:04.412185 expected per epoch 0:11:49.479348\n",
      "[0.274/10] loss(0.04372752457857132) elapsed 0:00:04.621973 expected per epoch 0:12:23.213258\n",
      "[0.280/10] loss(0.058008402585983276) elapsed 0:00:04.571746 expected per epoch 0:12:15.136757\n",
      "[0.286/10] loss(0.11139646917581558) elapsed 0:00:04.513167 expected per epoch 0:12:05.717254\n",
      "[0.292/10] loss(0.0436510294675827) elapsed 0:00:04.748422 expected per epoch 0:12:43.546258\n",
      "[0.299/10] loss(0.0896177589893341) elapsed 0:00:04.737119 expected per epoch 0:12:41.728735\n",
      "[0.305/10] loss(0.1107046902179718) elapsed 0:00:04.473999 expected per epoch 0:11:59.419039\n",
      "[0.311/10] loss(0.13884586095809937) elapsed 0:00:04.472036 expected per epoch 0:11:59.103389\n",
      "[0.317/10] loss(0.07556195557117462) elapsed 0:00:04.516040 expected per epoch 0:12:06.179232\n",
      "[0.323/10] loss(0.06802324950695038) elapsed 0:00:04.587940 expected per epoch 0:12:17.740752\n",
      "[0.330/10] loss(0.07950229942798615) elapsed 0:00:04.465074 expected per epoch 0:11:57.983899\n",
      "[0.336/10] loss(0.08156269043684006) elapsed 0:00:04.472857 expected per epoch 0:11:59.235406\n",
      "[0.342/10] loss(0.043242473155260086) elapsed 0:00:04.528148 expected per epoch 0:12:08.126198\n",
      "[0.348/10] loss(0.07045087218284607) elapsed 0:00:04.527802 expected per epoch 0:12:08.070562\n",
      "[0.354/10] loss(0.074930839240551) elapsed 0:00:04.443478 expected per epoch 0:11:54.511262\n",
      "[0.361/10] loss(0.05276231840252876) elapsed 0:00:04.417129 expected per epoch 0:11:50.274343\n",
      "[0.367/10] loss(0.06644894182682037) elapsed 0:00:04.415222 expected per epoch 0:11:49.967698\n",
      "[0.373/10] loss(0.053561389446258545) elapsed 0:00:04.412178 expected per epoch 0:11:49.478222\n",
      "[0.379/10] loss(0.05535676330327988) elapsed 0:00:04.412598 expected per epoch 0:11:49.545758\n",
      "[0.386/10] loss(0.04615755379199982) elapsed 0:00:04.415773 expected per epoch 0:11:50.056298\n",
      "[0.392/10] loss(0.11378232389688492) elapsed 0:00:04.410967 expected per epoch 0:11:49.283494\n",
      "[0.398/10] loss(0.04041058197617531) elapsed 0:00:04.411429 expected per epoch 0:11:49.357783\n",
      "[0.404/10] loss(0.11872045695781708) elapsed 0:00:04.410840 expected per epoch 0:11:49.263072\n",
      "[0.410/10] loss(0.04546918347477913) elapsed 0:00:04.419107 expected per epoch 0:11:50.592406\n",
      "[0.417/10] loss(0.07882803678512573) elapsed 0:00:04.412152 expected per epoch 0:11:49.474042\n",
      "[0.423/10] loss(0.07606318593025208) elapsed 0:00:04.431614 expected per epoch 0:11:52.603531\n",
      "[0.429/10] loss(0.060119062662124634) elapsed 0:00:04.485650 expected per epoch 0:12:01.292520\n",
      "[0.435/10] loss(0.04355202615261078) elapsed 0:00:04.606712 expected per epoch 0:12:20.759290\n",
      "[0.442/10] loss(0.023491691797971725) elapsed 0:00:04.413973 expected per epoch 0:11:49.766858\n",
      "[0.448/10] loss(0.07909882813692093) elapsed 0:00:04.411579 expected per epoch 0:11:49.381903\n",
      "[0.454/10] loss(0.08901125937700272) elapsed 0:00:04.415907 expected per epoch 0:11:50.077846\n",
      "[0.460/10] loss(0.08382870256900787) elapsed 0:00:04.412714 expected per epoch 0:11:49.564411\n",
      "[0.466/10] loss(0.0471000112593174) elapsed 0:00:04.417000 expected per epoch 0:11:50.253600\n",
      "[0.473/10] loss(0.029837829992175102) elapsed 0:00:04.414130 expected per epoch 0:11:49.792104\n",
      "[0.479/10] loss(0.06314203888177872) elapsed 0:00:04.484130 expected per epoch 0:12:01.048104\n",
      "[0.485/10] loss(0.035990145057439804) elapsed 0:00:04.552020 expected per epoch 0:12:11.964816\n",
      "[0.491/10] loss(0.13432815670967102) elapsed 0:00:04.412811 expected per epoch 0:11:49.580009\n",
      "[0.498/10] loss(0.06137796491384506) elapsed 0:00:04.411677 expected per epoch 0:11:49.397662\n",
      "[0.504/10] loss(0.1945657730102539) elapsed 0:00:04.412965 expected per epoch 0:11:49.604772\n",
      "[0.510/10] loss(0.22591650485992432) elapsed 0:00:04.514517 expected per epoch 0:12:05.934334\n",
      "[0.516/10] loss(0.27994033694267273) elapsed 0:00:04.412644 expected per epoch 0:11:49.553155\n",
      "[0.522/10] loss(0.1685241460800171) elapsed 0:00:04.424919 expected per epoch 0:11:51.526975\n",
      "[0.529/10] loss(0.08093898743391037) elapsed 0:00:04.415367 expected per epoch 0:11:49.991014\n",
      "[0.535/10] loss(0.11626597493886948) elapsed 0:00:04.415459 expected per epoch 0:11:50.005807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.541/10] loss(0.16070803999900818) elapsed 0:00:04.519273 expected per epoch 0:12:06.699098\n",
      "[0.547/10] loss(0.10669425874948502) elapsed 0:00:04.708723 expected per epoch 0:12:37.162658\n",
      "[0.553/10] loss(0.04541968181729317) elapsed 0:00:04.741950 expected per epoch 0:12:42.505560\n",
      "[0.560/10] loss(0.14954420924186707) elapsed 0:00:04.450357 expected per epoch 0:11:55.617406\n",
      "[0.566/10] loss(0.17878364026546478) elapsed 0:00:04.415768 expected per epoch 0:11:50.055494\n",
      "[0.572/10] loss(0.11978338658809662) elapsed 0:00:04.629627 expected per epoch 0:12:24.444022\n",
      "[0.578/10] loss(0.06506477296352386) elapsed 0:00:04.522081 expected per epoch 0:12:07.150625\n",
      "[0.585/10] loss(0.09001333266496658) elapsed 0:00:04.414037 expected per epoch 0:11:49.777150\n",
      "[0.591/10] loss(0.02096983790397644) elapsed 0:00:04.419727 expected per epoch 0:11:50.692102\n",
      "[0.597/10] loss(0.25389522314071655) elapsed 0:00:04.414193 expected per epoch 0:11:49.802234\n",
      "[0.603/10] loss(0.03452462702989578) elapsed 0:00:04.416004 expected per epoch 0:11:50.093443\n",
      "[0.609/10] loss(0.628679096698761) elapsed 0:00:04.415674 expected per epoch 0:11:50.040379\n",
      "[0.616/10] loss(0.05731708183884621) elapsed 0:00:04.415592 expected per epoch 0:11:50.027194\n",
      "[0.622/10] loss(0.08632010966539383) elapsed 0:00:04.413219 expected per epoch 0:11:49.645615\n",
      "[0.628/10] loss(0.2650580406188965) elapsed 0:00:04.410986 expected per epoch 0:11:49.286549\n",
      "[0.634/10] loss(0.25918808579444885) elapsed 0:00:04.411581 expected per epoch 0:11:49.382225\n",
      "[0.641/10] loss(0.6992540955543518) elapsed 0:00:04.416844 expected per epoch 0:11:50.228515\n",
      "[0.647/10] loss(0.087490513920784) elapsed 0:00:04.409377 expected per epoch 0:11:49.027822\n",
      "[0.653/10] loss(0.22290247678756714) elapsed 0:00:04.477068 expected per epoch 0:11:59.912534\n",
      "[0.659/10] loss(0.16301791369915009) elapsed 0:00:04.462516 expected per epoch 0:11:57.572573\n",
      "[0.665/10] loss(0.07697878777980804) elapsed 0:00:04.490127 expected per epoch 0:12:02.012422\n",
      "[0.672/10] loss(0.2249707728624344) elapsed 0:00:04.415972 expected per epoch 0:11:50.088298\n",
      "[0.678/10] loss(0.21393729746341705) elapsed 0:00:04.419011 expected per epoch 0:11:50.576969\n",
      "[0.684/10] loss(0.2403535097837448) elapsed 0:00:04.408246 expected per epoch 0:11:48.845957\n",
      "[0.690/10] loss(0.3134456276893616) elapsed 0:00:04.416930 expected per epoch 0:11:50.242344\n",
      "[0.697/10] loss(0.1718248873949051) elapsed 0:00:04.415939 expected per epoch 0:11:50.082991\n",
      "[0.703/10] loss(0.10041479021310806) elapsed 0:00:04.423813 expected per epoch 0:11:51.349130\n",
      "[0.709/10] loss(0.1421828269958496) elapsed 0:00:04.428969 expected per epoch 0:11:52.178215\n",
      "[0.715/10] loss(0.20484301447868347) elapsed 0:00:04.413633 expected per epoch 0:11:49.712186\n",
      "[0.721/10] loss(0.12406865507364273) elapsed 0:00:04.409013 expected per epoch 0:11:48.969290\n",
      "[0.728/10] loss(0.09382420033216476) elapsed 0:00:04.635636 expected per epoch 0:12:25.410269\n",
      "[0.734/10] loss(0.25762853026390076) elapsed 0:00:04.439771 expected per epoch 0:11:53.915177\n",
      "[0.740/10] loss(0.24156732857227325) elapsed 0:00:04.540068 expected per epoch 0:12:10.042934\n",
      "[0.746/10] loss(0.13184458017349243) elapsed 0:00:04.419220 expected per epoch 0:11:50.610576\n",
      "[0.752/10] loss(0.17807011306285858) elapsed 0:00:04.418482 expected per epoch 0:11:50.491906\n",
      "[0.759/10] loss(0.1399935781955719) elapsed 0:00:04.413821 expected per epoch 0:11:49.742417\n",
      "[0.765/10] loss(0.04026467353105545) elapsed 0:00:04.416219 expected per epoch 0:11:50.128015\n",
      "[0.771/10] loss(0.1086701974272728) elapsed 0:00:04.417753 expected per epoch 0:11:50.374682\n",
      "[0.777/10] loss(0.12403516471385956) elapsed 0:00:04.417056 expected per epoch 0:11:50.262605\n",
      "[0.784/10] loss(0.09577362984418869) elapsed 0:00:04.417019 expected per epoch 0:11:50.256655\n",
      "[0.790/10] loss(0.12779584527015686) elapsed 0:00:04.414870 expected per epoch 0:11:49.911096\n",
      "[0.796/10] loss(0.17132078111171722) elapsed 0:00:04.452449 expected per epoch 0:11:55.953799\n",
      "[0.802/10] loss(0.06890478730201721) elapsed 0:00:04.607568 expected per epoch 0:12:20.896934\n",
      "[0.808/10] loss(0.10380709171295166) elapsed 0:00:04.410808 expected per epoch 0:11:49.257926\n",
      "[0.815/10] loss(0.052305467426776886) elapsed 0:00:04.417758 expected per epoch 0:11:50.375486\n",
      "[0.821/10] loss(0.10101982206106186) elapsed 0:00:04.417065 expected per epoch 0:11:50.264052\n",
      "[0.827/10] loss(0.744640588760376) elapsed 0:00:04.418952 expected per epoch 0:11:50.567482\n",
      "[0.833/10] loss(0.07311361283063889) elapsed 0:00:04.420098 expected per epoch 0:11:50.751758\n",
      "[0.840/10] loss(0.28336241841316223) elapsed 0:00:04.438208 expected per epoch 0:11:53.663846\n",
      "[0.846/10] loss(0.16380305588245392) elapsed 0:00:04.416752 expected per epoch 0:11:50.213722\n",
      "[0.852/10] loss(0.2292538732290268) elapsed 0:00:04.418272 expected per epoch 0:11:50.458138\n",
      "[0.858/10] loss(0.10724165290594101) elapsed 0:00:04.414114 expected per epoch 0:11:49.789531\n",
      "[0.864/10] loss(0.24909672141075134) elapsed 0:00:04.410564 expected per epoch 0:11:49.218691\n",
      "[0.871/10] loss(0.10623306035995483) elapsed 0:00:04.414896 expected per epoch 0:11:49.915277\n",
      "[0.877/10] loss(0.3226344585418701) elapsed 0:00:04.416022 expected per epoch 0:11:50.096338\n",
      "[0.883/10] loss(0.14014121890068054) elapsed 0:00:04.419312 expected per epoch 0:11:50.625370\n",
      "[0.889/10] loss(0.11439881473779678) elapsed 0:00:04.649341 expected per epoch 0:12:27.614033\n",
      "[0.896/10] loss(0.17773255705833435) elapsed 0:00:04.436652 expected per epoch 0:11:53.413642\n",
      "[0.902/10] loss(0.07459451258182526) elapsed 0:00:04.416625 expected per epoch 0:11:50.193300\n",
      "[0.908/10] loss(0.039906974881887436) elapsed 0:00:04.412704 expected per epoch 0:11:49.562803\n",
      "[0.914/10] loss(0.08744635432958603) elapsed 0:00:04.418280 expected per epoch 0:11:50.459424\n",
      "[0.920/10] loss(0.06636807322502136) elapsed 0:00:04.487245 expected per epoch 0:12:01.548996\n",
      "[0.927/10] loss(0.044904910027980804) elapsed 0:00:04.771833 expected per epoch 0:12:47.310746\n",
      "[0.933/10] loss(0.07188132405281067) elapsed 0:00:04.584400 expected per epoch 0:12:17.171520\n",
      "[0.939/10] loss(0.07517749071121216) elapsed 0:00:04.550503 expected per epoch 0:12:11.720882\n",
      "[0.945/10] loss(0.052082642912864685) elapsed 0:00:04.417006 expected per epoch 0:11:50.254565\n",
      "[0.951/10] loss(0.1341215819120407) elapsed 0:00:04.411355 expected per epoch 0:11:49.345884\n",
      "[0.958/10] loss(0.10898247361183167) elapsed 0:00:04.414879 expected per epoch 0:11:49.912543\n",
      "[0.964/10] loss(0.03004051372408867) elapsed 0:00:04.415628 expected per epoch 0:11:50.032982\n",
      "[0.970/10] loss(0.0707162618637085) elapsed 0:00:04.411711 expected per epoch 0:11:49.403129\n",
      "[0.976/10] loss(0.1446990966796875) elapsed 0:00:04.407938 expected per epoch 0:11:48.796430\n",
      "[0.983/10] loss(0.10117676854133606) elapsed 0:00:04.410470 expected per epoch 0:11:49.203576\n",
      "[0.989/10] loss(0.06326897442340851) elapsed 0:00:04.413458 expected per epoch 0:11:49.684046\n",
      "[0.995/10] loss(0.17516371607780457) elapsed 0:00:04.414058 expected per epoch 0:11:49.780526\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/workspace/user-workspace/Fire_mountain/Madfalcon/base/main.py\", line 162, in <module>\n",
      "    out = model(i)\n",
      "  File \"/home/workspace/user-workspace/lib/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/workspace/user-workspace/lib/torchvision/models/segmentation/_utils.py\", line 24, in forward\n",
      "    x = self.classifier(x)\n",
      "  File \"/home/workspace/user-workspace/lib/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/workspace/user-workspace/lib/torch/nn/modules/container.py\", line 117, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/workspace/user-workspace/lib/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/workspace/user-workspace/lib/torchvision/models/segmentation/deeplabv3.py\", line 91, in forward\n",
      "    res.append(conv(x))\n",
      "  File \"/home/workspace/user-workspace/lib/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/workspace/user-workspace/lib/torchvision/models/segmentation/deeplabv3.py\", line 61, in forward\n",
      "    x = mod(x)\n",
      "  File \"/home/workspace/user-workspace/lib/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/workspace/user-workspace/lib/torch/nn/modules/batchnorm.py\", line 131, in forward\n",
      "    return F.batch_norm(\n",
      "  File \"/home/workspace/user-workspace/lib/torch/nn/functional.py\", line 2054, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/workspace/user-workspace/lib/torch/nn/functional.py\", line 2037, in _verify_batch_size\n",
      "    raise ValueError('Expected more than 1 value per channel when training, got input size {}'.format(size))\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "!python 'baseline/main.py' \\\n",
    "    --lr 0.0001 \\\n",
    "    --num_epochs 10 \\\n",
    "    --original_ep 5 \\\n",
    "    --print_iter 5 \\\n",
    "    --batch 4 \\\n",
    "    --mode 'train' \\\n",
    "    --load_trained_model True \\\n",
    "    --model_name '/home/workspace/user-workspace/Fire_mountain/Madfalcon/model_saved/best_model_128_ep5.pth' \\\n",
    "    --save_model_dir '/home/workspace/user-workspace/Fire_mountain/Madfalcon/model_saved/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n",
      "Predict mode\n",
      "write output\n"
     ]
    }
   ],
   "source": [
    "!python 'baseline/main.py' \\\n",
    "    --mode 'test' \\\n",
    "    --prediction_file \"result/prediction.csv\"\\\n",
    "    --model_name 'model_saved/best_model_128.pth' \\\n",
    "    --load_trained_model True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "307afa9c125f4eab844dd5298312ab09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=512.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121851</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121852</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121853</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121854</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121855</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121856 rows × 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0  1  2  3  4  5  6  7  8  9  ...  502  503  504  505  506  507  508  \\\n",
       "0       8  8  8  8  8  8  8  8  8  8  ...    8    8    8    8    8    8    8   \n",
       "1       8  8  8  8  8  8  8  8  8  8  ...    8    8    8    8    8    8    8   \n",
       "2       8  8  8  8  8  8  8  8  8  8  ...    8    8    8    8    8    8    8   \n",
       "3       8  8  8  8  8  8  8  8  8  8  ...    8    8    8    8    8    8    8   \n",
       "4       8  8  8  8  8  8  8  8  8  8  ...    8    8    8    8    8    8    8   \n",
       "...    .. .. .. .. .. .. .. .. .. ..  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "121851  1  1  1  1  1  1  1  1  1  1  ...    1    1    1    1    1    1    1   \n",
       "121852  1  1  1  1  1  1  1  1  1  1  ...    1    1    1    1    1    1    1   \n",
       "121853  1  1  1  1  1  1  1  1  1  1  ...    1    1    1    1    1    1    1   \n",
       "121854  1  1  1  1  1  1  1  1  1  1  ...    1    1    1    1    1    1    1   \n",
       "121855  1  1  1  1  1  1  1  1  1  1  ...    1    1    1    1    1    1    1   \n",
       "\n",
       "        509  510  511  \n",
       "0         8    8    8  \n",
       "1         8    8    8  \n",
       "2         8    8    8  \n",
       "3         8    8    8  \n",
       "4         8    8    8  \n",
       "...     ...  ...  ...  \n",
       "121851    1    1    1  \n",
       "121852    1    1    1  \n",
       "121853    1    1    1  \n",
       "121854    1    1    1  \n",
       "121855    1    1    1  \n",
       "\n",
       "[121856 rows x 512 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make submmision csv\n",
    "# preprocess에서 진행했던 전처리를 다시 초기화\n",
    "result_df = pd.read_csv('result/prediction.csv')\n",
    "for col in tqdm(result_df.columns):\n",
    "    result_df[col] = result_df[col] + 1\n",
    "result_df.to_csv('result/prediction.csv',index=None)\n",
    "result_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
