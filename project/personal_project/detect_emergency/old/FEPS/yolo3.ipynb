{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os.path\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from bokeh.plotting import figure #pip install bokeh\n",
    "from bokeh.io import output_notebook, show, push_notebook\n",
    "\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "\n",
    "def imshow(tit, image) :\n",
    "    plt.title(tit)    \n",
    "    if len(image.shape) == 3 :\n",
    "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    else :\n",
    "        plt.imshow(image, cmap=\"gray\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def create_win(frames, scale=1.0) :    \n",
    "    global myImage\n",
    "    \n",
    "    all = []\n",
    "    for f in frames :\n",
    "        if len(f.shape ) !=  3 : f = cv2.cvtColor(f, cv2.COLOR_GRAY2BGR)\n",
    "        all.append(f)\n",
    "    frame = np.vstack(all)\n",
    "    \n",
    "    fr=cv2.cvtColor(frame, cv2.COLOR_BGR2RGBA) # because Bokeh expects a RGBA image\n",
    "    fr=cv2.flip(fr, -1) # because Bokeh flips vertically\n",
    "    width=fr.shape[1]\n",
    "    height=fr.shape[0]    \n",
    "\n",
    "    p = figure(x_range=(0,width), y_range=(0,height), output_backend=\"webgl\", width=int(width*scale), height=int(height*scale))    \n",
    "    myImage = p.image_rgba(image=[fr], x=0, y=0, dw=width, dh=height)\n",
    "    show(p, notebook_handle=True)   \n",
    "    \n",
    "    \n",
    "def update_win(frames) :\n",
    "    \n",
    "    all = []\n",
    "    for f in frames :\n",
    "        #print(len(f.shape))\n",
    "        if len(f.shape ) !=  3 : f = cv2.cvtColor(f, cv2.COLOR_GRAY2BGR)\n",
    "        all.append(f)\n",
    "    frame = np.vstack(all)\n",
    "    \n",
    "    fr=cv2.cvtColor(frame, cv2.COLOR_BGR2RGBA)\n",
    "    fr=cv2.flip(fr, 0)\n",
    "    myImage.data_source.data['image']=[fr]\n",
    "    push_notebook()\n",
    "    # Initialize the parameters\n",
    "confThreshold = 0.3  #Confidence threshold, 오브젝트일 확률\n",
    "nmsThreshold = 0.4   #Non-maximum suppression threshold , 거리가 가까운애들은 하나의 그룹으로 보겟다, 주변보다 상대적으로 값이 높거나 낮거나 하는 애를 뽑겠다.\n",
    "\n",
    "#YOLO v3는 영상을 무조건 416 사이즈로 변경\n",
    "inpWidth = 416       #Width of network's input image\n",
    "inpHeight = 416      #Height of network's input image\n",
    "\n",
    "# Load names of classes\n",
    "classesFile = \"cfg/one.names\" \n",
    "classes = None\n",
    "with open(classesFile, 'rt') as f:\n",
    "    classes = f.read().rstrip('\\n').split('\\n')\n",
    "print(classes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Get the names of the output layers\n",
    "def getOutputsNames(net):\n",
    "    # Get the names of all the layers in the network\n",
    "    layersNames = net.getLayerNames() #네트웍의 모든 이름을 가져오는 함수 ,총 갯수는 254개, 실제 레이어는 100 몇개,\n",
    "    # Get the names of the output layers, i.e. the layers with unconnected outputs\n",
    "    return [layersNames[i[0] - 1] for i in net.getUnconnectedOutLayers()] #실제 output 위치는 getUnconnectedOutLayers에서 1뺌\n",
    "\n",
    "# Draw the predicted bounding box\n",
    "#사각형으로 바운딩한 곳을 표시\n",
    "def drawPred(frame, classId, conf, left, top, right, bottom): #클래스ID, 클래스에 대한 일치 확률,사각형 정보\n",
    "    # Draw a bounding box.\n",
    "    cv2.rectangle(frame, (left, top), (right, bottom), (255, 178, 50), 3)\n",
    "    \n",
    "    label = '%.2f' % conf\n",
    "        \n",
    "    # Get the label for the class name and its confidence\n",
    "    if classes:\n",
    "        assert(classId < len(classes))\n",
    "        label = '%s:%s' % (classes[classId], label)\n",
    "\n",
    "    #Display the label at the top of the bounding box\n",
    "    labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "    top = max(top, labelSize[1])\n",
    "    cv2.rectangle(frame, (left, top - round(1.5*labelSize[1])), (left + round(1.5*labelSize[0]), top + baseLine), (255, 255, 255), cv2.FILLED)\n",
    "    cv2.putText(frame, label, (left, top), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0,0,0), 1)\n",
    "\n",
    "# Remove the bounding boxes with low confidence using non-maxima suppression\n",
    "#\n",
    "def postprocess(frame, outs):\n",
    "    frameHeight = frame.shape[0]\n",
    "    frameWidth = frame.shape[1]\n",
    "\n",
    "    # Scan through all the bounding boxes output from the network and keep only the\n",
    "    # ones with high confidence scores. Assign the box's class label as the class with the highest score.\n",
    "    classIds = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:] #확률 80개의 값을 가져옴\n",
    "            classId = np.argmax(scores) #확률에서 높은거 가져옴\n",
    "            confidence = scores[classId] #확률 값 가져옴\n",
    "            if confidence > confThreshold: # confThreshold보다 더 높을 경우, 박스를 만듬\n",
    "                center_x = int(detection[0] * frameWidth)\n",
    "                center_y = int(detection[1] * frameHeight)\n",
    "                width = int(detection[2] * frameWidth)\n",
    "                height = int(detection[3] * frameHeight)\n",
    "                left = int(center_x - width / 2)\n",
    "                top = int(center_y - height / 2)\n",
    "                classIds.append(classId)\n",
    "                confidences.append(float(confidence))\n",
    "                boxes.append([left, top, width, height])\n",
    "        \n",
    "    # Perform non maximum suppression to eliminate redundant overlapping boxes with\n",
    "    # lower confidences.\n",
    "    \n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, confThreshold, nmsThreshold)\n",
    "    #같은 포인트에서 다수의 바운딩 박스가 생성되어 있는걸 좀더 정확하게 판별해서 최소화 해줌\n",
    "    \n",
    "    for i in indices:\n",
    "        i = i[0] #2차원 행렬이므로 \n",
    "        box = boxes[i]\n",
    "        left = box[0]\n",
    "        top = box[1]\n",
    "        width = box[2]\n",
    "        height = box[3]\n",
    "        drawPred(frame, classIds[i], confidences[i], left, top, left + width, top + height)\n",
    "        \n",
    "# Give the configuration and weight files for the model and load the network using them.\n",
    "modelConfiguration = \"cfg/one.cfg\" #네트워크 구조체(CNN 필터 값들)가 포함되어있다, #컨피그 상에서 실제로 Yolo 관련 컨피그가 3개가 있다.\n",
    "modelWeights = \"cfg/one_class_v1_1800.weights\"\n",
    "        \n",
    "\n",
    "net = cv2.dnn.readNetFromDarknet(modelConfiguration, modelWeights)\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "        \n",
    "# print(\"YOLO Video process\")\n",
    "# cap = cv2.VideoCapture(\"static/videos/swoon.mp4\")\n",
    "# frame_width = int(cap.get(3))\n",
    "# frame_height = int(cap.get(4))\n",
    "# print('width :%d, height : %d' % (frame_width, frame_height))\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'XVID') #운영체제별로 지원하는게 다름 확인필요\n",
    "# out = cv2.VideoWriter('static/video_result/swoon.avi', fourcc, 29.0, (frame_width, frame_height)) \n",
    "# i = 0\n",
    "# while(True):\n",
    "#     hasFrame, frame = cap.read()    # Read 결과와 frame\n",
    "#     if not hasFrame:\n",
    "#         break\n",
    "#     #print(hasFrame)\n",
    "#     #print(frame)\n",
    "#     print(i)\n",
    "#     if(hasFrame) :\n",
    "#         if i > 3300 and i < 7250:\n",
    "#             print(i, ': caputer ..')\n",
    "#             blob = cv2.dnn.blobFromImage(frame, 1/255, (inpWidth, inpHeight), [0,0,0], 1, crop=False)\n",
    "#             net.setInput(blob)\n",
    "#             outs = net.forward(getOutputsNames(net))\n",
    "#             postprocess(frame, outs)\n",
    "#             #cv2.imshow('frame_color', frame)    # 컬러 화면 출력\n",
    "#             out.write(frame)\n",
    "#         if i == 300:\n",
    "#             break\n",
    "#     i += 1\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "print(\"YOLO Video process\")\n",
    "cap = cv2.VideoCapture(\"static/videos/swoon.mp4\")\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "print('width :%d, height : %d' % (frame_width, frame_height))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID') #운영체제별로 지원하는게 다름 확인필요\n",
    "out = cv2.VideoWriter('static/video_result/swoon.avi', fourcc, 29.0, (frame_width, frame_height)) \n",
    "i = 0\n",
    "while(True):\n",
    "    hasFrame, frame = cap.read()    # Read 결과와 frame\n",
    "    if not hasFrame:\n",
    "        break\n",
    "    #print(hasFrame)\n",
    "    #print(frame)\n",
    "    print(i)\n",
    "    if(hasFrame) :\n",
    "        if i > 1 and i < 7250:\n",
    "            print(i, ': caputer ..')\n",
    "            start_time = time.time()\n",
    "            blob = cv2.dnn.blobFromImage(frame, 1/255, (inpWidth, inpHeight), [0,0,0], 1, crop=False)\n",
    "            net.setInput(blob)\n",
    "            outs = net.forward(getOutputsNames(net))\n",
    "            postprocess(frame, outs)\n",
    "            #cv2.imshow('frame_color', frame)    # 컬러 화면 출력\n",
    "            out.write(frame)\n",
    "            end_time = time.time()\n",
    "            print(f\"inference_time: {round(end_time-start_time,2)}\")\n",
    "        if i == 300:\n",
    "            break\n",
    "    i += 1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
